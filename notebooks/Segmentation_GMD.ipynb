{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b8f10f3",
   "metadata": {},
   "source": [
    "# Segmentation using pretrained G_MD.tar\n",
    "\n",
    "This notebook runs a pretrained AtomAI model archive (`G_MD.tar`) on an input STEM image and extracts atomic coordinates.\n",
    "\n",
    "Colab notes: mount Google Drive or upload the `G_MD.tar` archive. Install requirements in the first cell and run top-to-bottom. If no servers are available, a synthetic perfect-crystal image will be generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7026d160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (runs quickly if already present)\n",
    "# AtomAI is installed from GitHub; matplotlib/pillow for plotting.\n",
    "!pip install --quiet git+https://github.com/pycroscopy/atomai\n",
    "!pip install --quiet matplotlib pillow\n",
    "print('Installed/ensured atomai, matplotlib, pillow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450b4118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic imports\n",
    "import os\n",
    "import tempfile\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "# Keep the outputs directory consistent\n",
    "OUT_DIR = 'notebooks/output'\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "print('OUT_DIR =', OUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6074d1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to get a simulated STEM image via NotebookClient (same approach as Aberrations.ipynb).\n",
    "# If the servers are not running, fall back to a synthetic generator.\n",
    "img = None\n",
    "try:\n",
    "    from asyncroscopy.clients.notebook_client import NotebookClient\n",
    "    tem = NotebookClient.connect(host='localhost', port=9000)\n",
    "    image_args = {'scanning_detector': 'HAADF', 'size': 512, 'dwell_time': 10e-6}\n",
    "    img = tem.send_command('AS', 'get_scanned_image', image_args)\n",
    "    print('Obtained image from AS_server_SimAtomRes via NotebookClient')\n",
    "except Exception as e:\n",
    "    print('Could not get image from servers â€” falling back to synthetic generator. Error:', e)\n",
    "    def generate_perfect_crystal(size=512, period_x=16, period_y=16, seed=0):\n",
    "        import numpy as _np\n",
    "        rng = _np.random.default_rng(seed)\n",
    "        x = _np.arange(size)\n",
    "        y = _np.arange(size)\n",
    "        X, Y = _np.meshgrid(x, y)\n",
    "        image = 0.5 * (_np.cos(2 * _np.pi * X / period_x) + 1)\n",
    "        image += 0.5 * (_np.cos(2 * _np.pi * Y / period_y) + 1)\n",
    "        image = (image - image.min()) / (image.max() - image.min())\n",
    "        noise = rng.normal(0, 0.05, image.shape)\n",
    "        image = _np.clip(image + noise, 0, 1)\n",
    "        return image.astype(_np.float32)\n",
    "    img = generate_perfect_crystal()\n",
    "\n",
    "# Normalize and ensure 2D float array\n",
    "if isinstance(img, Image.Image):\n",
    "    img = np.array(img.convert('F'), dtype=np.float32)\n",
    "img = np.asarray(img, dtype=np.float32)\n",
    "if img.ndim == 3 and img.shape[0] == 1:\n",
    "    img = img[0]\n",
    "elif img.ndim == 3 and img.shape[-1] == 1:\n",
    "    img = img[..., 0]\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(img, cmap='gray', origin='lower')\n",
    "plt.title('Input Atomic-resolution Image')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# keep 'img' variable for downstream cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57979269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model archive location options for Colab:\n",
    "# 1) Mount Google Drive and place G_MD.tar in MyDrive, or\n",
    "# 2) Upload the file manually using the upload widget below.\n",
    "\n",
    "# Try Google Drive first (optional). If you are NOT using Drive, skip mounting.\n",
    "use_drive = True\n",
    "model_tar_path = '/content/G_MD.tar'\n",
    "if use_drive:\n",
    "    try:\n",
    "        from google.colab import drive\n",
    "        drive.mount('/content/drive')\n",
    "        drive_path = '/content/drive/MyDrive/G_MD.tar'\n",
    "        if os.path.exists(drive_path):\n",
    "            model_tar_path = drive_path\n",
    "            print('Found model in Google Drive at', drive_path)\n",
    "        else:\n",
    "            print('Did not find model at', drive_path, '\\nYou can upload it with the cell below or set use_drive=False to skip Drive mounting.')\n",
    "    except Exception as e:\n",
    "        print('Drive mount failed or not in Colab environment:', e)\n",
    "\n",
    "# Upload helper (runs in Colab) - will write to /content/G_MD.tar\n",
    "if not os.path.exists(model_tar_path):\n",
    "    try:\n",
    "        from google.colab import files\n",
    "        print('Please upload G_MD.tar via the file picker...')\n",
    "        uploaded = files.upload()\n",
    "        for name in uploaded:\n",
    "            if name.endswith('.tar') or name.endswith('.zip') or name.endswith('.tar.gz'):\n",
    "                src = name\n",
    "                dst = model_tar_path\n",
    "                os.rename(src, dst)\n",
    "                print('Saved uploaded file to', dst)\n",
    "                break\n",
    "    except Exception as e:\n",
    "        print('Upload skipped or not running in Colab filepicker:', e)\n",
    "\n",
    "print('Using model archive at', model_tar_path)\n",
    "model_tar_path = os.path.expanduser(model_tar_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc4ed81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load atomai and attempt to load the pretrained model\n",
    "import atomai as aai\n",
    "model = None\n",
    "# Prefer letting atomai load the archive directly (it handles several formats)\n",
    "if os.path.exists(model_tar_path):\n",
    "    try:\n",
    "        print('Attempting to load model archive with atomai.models.load_model(...)')\n",
    "        model = aai.models.load_model(model_tar_path)\n",
    "        print('Loaded model from archive using atomai.models.load_model')\n",
    "    except Exception as e:\n",
    "        print('atomai.models.load_model failed, will try to extract weights and load manually:', e)\n",
    "        # Try to extract common weight files and load state_dict if present\n",
    "        try:\n",
    "            import tarfile, zipfile\n",
    "            tmpd = tempfile.mkdtemp(prefix='G_MD_')\n",
    "            # try tar first, then zip\n",
    "            try:\n",
    "                with tarfile.open(model_tar_path, 'r') as tar:\n",
    "                    tar.extractall(path=tmpd)\n",
    "            except Exception:\n",
    "                try:\n",
    "                    with zipfile.ZipFile(model_tar_path, 'r') as zf:\n",
    "                        zf.extractall(tmpd)\n",
    "                except Exception as e2:\n",
    "                    print('Failed to extract archive:', e2)\n",
    "            # search for .pt/.pth files\n",
    "            model_file = None\n",
    "            for root, _, files in os.walk(tmpd):\n",
    "                for f in files:\n",
    "                    if f.endswith(('.pt', '.pth')):\n",
    "                        model_file = os.path.join(root, f)\n",
    "                        break\n",
    "                if model_file:\n",
    "                    break\n",
    "            if model_file:\n",
    "                try:\n",
    "                    state = torch.load(model_file, map_location='cpu')\n",
    "                    if isinstance(state, dict) and 'state_dict' in state:\n",
    "                        state_dict = state['state_dict']\n",
    "                    else:\n",
    "                        state_dict = state\n",
    "                    model = aai.models.Segmentor(nb_classes=3)\n",
    "                    model.net.load_state_dict(state_dict)\n",
    "                    print('Loaded weights into a Segmentor instance from', model_file)\n",
    "                except Exception as e3:\n",
    "                    print('Failed to load state_dict from', model_file, e3)\n",
    "        except Exception as e_extract:\n",
    "            print('Archive fallback/load failed:', e_extract)\n",
    "\n",
    "if model is None:\n",
    "    print('Falling back to an untrained Segmentor (results may not be meaningful)')\n",
    "    model = aai.models.Segmentor(nb_classes=3)\n",
    "\n",
    "# model is ready (may be untrained if loading failed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32db7d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare tensor and run prediction (robust to different nn_output shapes)\n",
    "X = torch.from_numpy(img[None, None, :, :]).float()\n",
    "coords = None\n",
    "nn_output = None\n",
    "try:\n",
    "    # prefer atom_find to get coordinates and segmentation map\n",
    "    nn_output, coords = model.predict(X, method='atom_find')\n",
    "    print('atom_find prediction returned types:', type(nn_output), type(coords))\n",
    "except Exception as e:\n",
    "    print('atom_find failed, trying generic predict:', e)\n",
    "    try:\n",
    "        nn_output = model.predict(X)\n",
    "    except Exception as e2:\n",
    "        print('predict failed, will fallback to simple threshold segmentation:', e2)\n",
    "\n",
    "# Helper to coerce nn_output into a 2D integer segmentation mask\n",
    "def nn_output_to_mask(nn_out):\n",
    "    if nn_out is None:\n",
    "        return (img > img.mean()).astype(np.int32)\n",
    "    a = np.asarray(nn_out)\n",
    "    # common shapes: (1, H, W, C), (1, C, H, W), (C, H, W), (H, W)\n",
    "    if a.ndim == 4 and a.shape[0] == 1 and (a.shape[-1] == 1 or a.shape[-1] > 1):\n",
    "        # (1, H, W, C) or (1, H, W, 1) -> take channel axis last\n",
    "        arr = a[0]\n",
    "        if arr.ndim == 3:\n",
    "            if arr.shape[-1] == 1:\n",
    "                return arr[...,0].astype(np.int32)\n",
    "            return np.argmax(arr, axis=-1).astype(np.int32)\n",
    "    if a.ndim == 4 and a.shape[1] > 1:\n",
    "        # (1, C, H, W) -> squeeze and argmax over channel dim 0\n",
    "        arr = a.squeeze(0)\n",
    "        return np.argmax(arr, axis=0).astype(np.int32)\n",
    "    if a.ndim == 3:\n",
    "        # (C, H, W) or (H, W, C)\n",
    "        if a.shape[0] in (1,2,3,4):\n",
    "            return np.argmax(a, axis=0).astype(np.int32)\n",
    "        else:\n",
    "            return np.argmax(a, axis=-1).astype(np.int32)\n",
    "    if a.ndim == 2:\n",
    "        return a.astype(np.int32)\n",
    "    # fallback\n",
    "    return (img > img.mean()).astype(np.int32)\n",
    "\n",
    "segmented = nn_output_to_mask(nn_output)\n",
    "print('Segmented mask shape:', segmented.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5903e253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize and save outputs\n",
    "fig, ax = plt.subplots(1,2, figsize=(14,6))\n",
    "ax[0].imshow(img, cmap='gray', origin='lower')\n",
    "cmap_colors = ['k','red','blue','green','yellow']\n",
    "cmap = ListedColormap(cmap_colors[: max(2, int(segmented.max())+1)])\n",
    "ax[0].imshow(segmented, cmap=cmap, alpha=0.5, origin='lower')\n",
    "ax[0].set_title('Segmentation Overlay')\n",
    "ax[0].axis('off')\n",
    "\n",
    "ax[1].imshow(img, cmap='gray', origin='lower')\n",
    "if coords is not None:\n",
    "    try:\n",
    "        coords_arr = coords[0] if isinstance(coords, dict) and 0 in coords else coords\n",
    "        coords_arr = np.asarray(coords_arr)\n",
    "        if coords_arr.ndim == 2 and coords_arr.shape[1] >= 2:\n",
    "            x = coords_arr[:,0]\n",
    "            y = coords_arr[:,1]\n",
    "            classes = coords_arr[:,2].astype(int) if coords_arr.shape[1] > 2 else np.zeros(len(x), dtype=int)\n",
    "            colors = {1:'red', 2:'blue', 3:'green'}\n",
    "            for cl in np.unique(classes):\n",
    "                if cl == 0:\n",
    "                    continue\n",
    "                mask = classes == cl\n",
    "                ax[1].scatter(x[mask], y[mask], s=30, c=colors.get(cl,'white'), label=f'Class {cl}', edgecolor='yellow')\n",
    "            ax[1].legend()\n",
    "    except Exception as e:\n",
    "        print('Failed to unpack coords for plotting:', e)\n",
    "\n",
    "ax[1].set_title('Detected Atom Coordinates')\n",
    "ax[1].axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Save artifacts\n",
    "np.save(os.path.join(OUT_DIR, 'segmented_mask.npy'), segmented)\n",
    "fig.savefig(os.path.join(OUT_DIR, 'segmentation_and_coords.png'), bbox_inches='tight', dpi=200)\n",
    "print('Saved segmented_mask.npy and segmentation_and_coords.png to', OUT_DIR)\n",
    "\n",
    "# If coords available, save CSV\n",
    "if coords is not None:\n",
    "    try:\n",
    "        coords_arr = coords[0] if isinstance(coords, dict) and 0 in coords else coords\n",
    "        coords_arr = np.asarray(coords_arr)\n",
    "        import csv\n",
    "        csv_path = os.path.join(OUT_DIR, 'coords.csv')\n",
    "        with open(csv_path, 'w', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(['x','y','class'])\n",
    "            for row in coords_arr:\n",
    "                writer.writerow([float(row[0]), float(row[1]), int(row[2]) if len(row)>2 else 0])\n",
    "        print('Saved coordinates CSV to', csv_path)\n",
    "    except Exception as e:\n",
    "        print('Failed to save coords CSV:', e)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
