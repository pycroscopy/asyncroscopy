{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Objective BO on Aberrations : c1-a1x-a1y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing uv\n",
    "\n",
    "To start, you'll want to have uv installed:\n",
    "\n",
    "https://docs.astral.sh/uv/getting-started/installation/\n",
    "\n",
    "\n",
    "**Next, run this in the terminal, from the parent directory:**\n",
    "\n",
    "    uv sync\n",
    "\n",
    "\n",
    "Now you will have the kernel used to run this notebook\n",
    "\n",
    "---\n",
    "\n",
    "## Running the Required Servers\n",
    "\n",
    "You need to run **three servers**, each in its own terminal:\n",
    "\n",
    "- `central_server.py`\n",
    "- `AS_server_SimAtomRes.py`\n",
    "- `Ceos_server_twin.py`\n",
    "\n",
    "### 1. Activate the Virtual Environment\n",
    "\n",
    "`uv` should have created a `.venv` directory for you.\n",
    "\n",
    "**On macOS / Linux:**\n",
    "\n",
    "    source .venv/bin/activate\n",
    "\n",
    "**On Windows (likely):**\n",
    "\n",
    "    source .venv/Scripts/activate\n",
    "\n",
    "You should now see the environment activated.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Start the Servers\n",
    "\n",
    "**Terminal 1 â€” Central Server**\n",
    "\n",
    "    source .venv/bin/activate\n",
    "    python -m asyncroscopy.servers.protocols.central_server\n",
    "\n",
    "**Terminal 2 â€” Atom Resolution Simulation Server**\n",
    "\n",
    "    source .venv/bin/activate\n",
    "    python -m asyncroscopy.servers.AS_server_SimAtomRes\n",
    "\n",
    "**Terminal 3 â€” CEOS Twin Server**\n",
    "\n",
    "    source .venv/bin/activate\n",
    "    python -m asyncroscopy.servers.Ceos_server_twin\n",
    "\n",
    "---\n",
    "\n",
    "You're now ready to run this notebook! ðŸš€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import ast\n",
    "sys.path.insert(0, '../')\n",
    "from asyncroscopy.clients.notebook_client import NotebookClient\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pyTEMlib\n",
    "from pyTEMlib import probe_tools as pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connections:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect the Client to the central (async) server\n",
    "tem = NotebookClient.connect(host='localhost',port=9000)\n",
    "\n",
    "# Tell the central server address of all connected instruments\n",
    "routing_table= {\"AS\": (\"localhost\", 9001),\n",
    "                \"Gatan\": (\"localhost\", 9002),\n",
    "                \"Ceos\": (\"localhost\", 9003),\n",
    "                \"Preacquired_AS\": (\"localhost\", 9004)}\n",
    "tem.send_command('Central',\"set_routing_table\", routing_table)\n",
    "\n",
    "# ConnectionResetError: [Errno 54] Connection reset by peer \n",
    "# in terminal, type:\n",
    "# lsof -i :9000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to the AutoScript computer and initialize microscope\n",
    "tem.send_command('AS',command='connect_AS',args={'host':'localhost','port':9001})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tem.send_command(destination = 'Ceos', command = 'getInfo', args = {})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Help commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we're routed to all instruments,\n",
    "# let's take an inventory of commands available on each instrument\n",
    "cmds = tem.send_command('AS', 'discover_commands')\n",
    "print(cmds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These two are working, but should be much better.\n",
    "tem.send_command('AS', command='get_help', args={'command_name':'connect_AS'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting the aberrations from known values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html><body>Aberrations [nm] for acceleration voltage: 200 kV<table><tr><td> C10 </td><td> 0.0 </tr><tr><td> C12a (A1) </td><td>                  0.0 <td> C12b (A1) </td><td>                  0.4 </tr><tr><td> C21a (B2) </td><td> -68.5 <td> C21b (B2)</td><td> 64.9     <td> C23a (A2) </td><td> 11.7 <td> C23b (A2) </td><td> -29.8 </tr><tr><td> C30 </td><td> 123.0 </tr><tr><td> C32a (S3) </td><td>                 95.3 <td> C32b (S3)</td><td>               -189.7 <td> C34a (A3) </td><td>                -47.5 <td> C34b (A3) </td><td>                -94.7 </tr><tr><td> C41a (B4) </td><td> -905 <td> C41b (B4) </td><td> 981     <td> C43a (D4) </td><td> 4.02e+03 <td> C43b (D4) </td><td> 981     <td> C45a (A4) </td><td> -4.7e+03 <td> C45b (A4)</td><td> -208 </tr><tr><td> C50 </td><td> 5.52e+05 </tr><tr><td> C52a </td><td>                 -0.0 <td> C52b </td><td>                  0.0 <td> C54a </td><td>                 -0.0 <td> C54b </td><td>                 -0.0 <td> C56a </td><td>             -36663.6 <td> C56b </td><td>              21356.1 </tr><tr><td> Cc </td><td> 1e+06 </tr></table></body></html>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "aberrations = pt.get_target_aberrations(\"Spectra300\", 60000)\n",
    "tem.send_command(destination = 'Ceos', command = 'uploadAberrations', args = aberrations)\n",
    "pt.print_aberrations(aberrations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# at any time, we can view the current aberrations\n",
    "# this should be implemented in the real ceos server as well\n",
    "ab = tem.send_command(destination = 'Ceos', command = 'getAberrations', args={})\n",
    "ab = ast.literal_eval(ab)\n",
    "pt.print_aberrations(ab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get an image:\n",
    "\n",
    "simulated with pystemsim inside the AS_server_SimAtomRes (working with the Ceos server)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_args = {'scanning_detector':'HAADF',\n",
    "                'size':512,\n",
    "                'dwell_time':10e-6}\n",
    "\n",
    "img = tem.send_command('AS','get_scanned_image', image_args)\n",
    "\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.title(\"Simulated STEM Image\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How it's actually working:\n",
    "![Structure Diagram](../DT_workflow.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### try changing an aberration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tem.send_command(destination = 'Ceos', command = 'correctAberration', args = {\"name\": 'C10', \"value\": -6})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_args = {'scanning_detector':'HAADF',\n",
    "                'size':512,\n",
    "                'dwell_time':10e-6}\n",
    "\n",
    "img = tem.send_command('AS','get_scanned_image', image_args)\n",
    "\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.title(\"Simulated STEM Image\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Lets do BO to tune the parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 set helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy import ndimage\n",
    "import numpy as np\n",
    "\n",
    "def contrast_rms(im, eps=1e-12):\n",
    "    m = np.mean(im)\n",
    "    return np.std(im) / (m + eps)\n",
    "\n",
    "def get_stem_image_contrast_and_fft(c10, c12a, c12b, plot_diagnostics=False):\n",
    "    ab['C10'] = c10\n",
    "    ab['C12a'] = c12a\n",
    "    ab['C12b'] = c12b\n",
    "\n",
    "    aberrations = {\n",
    "        \"C10\": float(c10),\n",
    "        \"C12a\": float(c12a),\n",
    "        \"C12b\": float(c12b),\n",
    "    }\n",
    "\n",
    "\n",
    "    tem.send_command(\n",
    "        destination=\"Ceos\",\n",
    "        command=\"uploadAberrations\",\n",
    "        args=aberrations,\n",
    "    )\n",
    "    # ommand = 'correctAberration' can be also used: Wondering if either is preferred due to speed?\n",
    "    # tem.send_command(destination = 'Ceos', command = 'correctAberration', args = {\"name\": 'C10', \"value\": -6})\n",
    "    \n",
    "    \n",
    "    image_args = {'scanning_detector':'HAADF',\n",
    "                    'size':512,\n",
    "                    'dwell_time':10e-6}\n",
    "\n",
    "    sim_im = tem.send_command('AS','get_scanned_image', image_args)\n",
    "\n",
    "    ####------> shall we add some noise here?\n",
    "    \n",
    "    contrast = contrast_rms(np.array(sim_im))\n",
    "    \n",
    "    sim_array = np.array(sim_im, dtype=float)\n",
    "    sim_array = (sim_array - sim_array.mean()) / sim_array.std()\n",
    "    \n",
    "    fft = np.fft.fft2(sim_array)\n",
    "    fft_shift = np.fft.fftshift(fft)\n",
    "    power = np.abs(fft_shift)**2\n",
    "    power_log = np.log1p(power)\n",
    "    \n",
    "    center = np.array(power.shape) // 2\n",
    "    y, x = np.ogrid[:power.shape[0], :power.shape[1]]\n",
    "    r = np.sqrt((x - center[1])**2 + (y - center[0])**2)\n",
    "    \n",
    "    power_log[center[0]-10:center[0]+10, center[1]-10:center[1]+10] = 0\n",
    "    \n",
    "    smoothed = ndimage.gaussian_filter(power_log, sigma=2)\n",
    "    \n",
    "    threshold = np.percentile(smoothed, 99.5)\n",
    "    peaks = smoothed > threshold\n",
    "    \n",
    "    labeled, num_peaks = ndimage.label(peaks)\n",
    "    \n",
    "    if num_peaks == 0:\n",
    "        fft_score = 0.0\n",
    "        max_radius = 0\n",
    "    else:\n",
    "        peak_distances = []\n",
    "        for i in range(1, num_peaks + 1):\n",
    "            peak_coords = np.where(labeled == i)\n",
    "            peak_y, peak_x = np.mean(peak_coords[0]), np.mean(peak_coords[1])\n",
    "            distance = np.sqrt((peak_x - center[1])**2 + (peak_y - center[0])**2)\n",
    "            peak_intensity = smoothed[labeled == i].max()\n",
    "            if distance > 15:\n",
    "                peak_distances.append((distance, peak_intensity))\n",
    "        \n",
    "        if len(peak_distances) > 0:\n",
    "            max_radius = max(d[0] for d in peak_distances)\n",
    "            fft_score = float(max_radius / min(center))\n",
    "        else:\n",
    "            max_radius = 0\n",
    "            fft_score = 0.0\n",
    "    \n",
    "    if plot_diagnostics:\n",
    "        fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "        \n",
    "        axes[0,0].imshow(sim_im, cmap='gray')\n",
    "        axes[0,0].set_title('Original Image')\n",
    "        \n",
    "        axes[0,1].imshow(power_log, cmap='hot')\n",
    "        axes[0,1].set_title('FFT Power (log)')\n",
    "        \n",
    "        axes[0,2].imshow(smoothed, cmap='hot')\n",
    "        axes[0,2].set_title('Smoothed FFT')\n",
    "        \n",
    "        axes[1,0].imshow(peaks, cmap='gray')\n",
    "        axes[1,0].set_title(f'Detected Peaks ({num_peaks})')\n",
    "        \n",
    "        axes[1,1].imshow(power_log, cmap='hot')\n",
    "        if num_peaks > 0:\n",
    "            for i in range(1, num_peaks + 1):\n",
    "                peak_coords = np.where(labeled == i)\n",
    "                peak_y, peak_x = np.mean(peak_coords[0]), np.mean(peak_coords[1])\n",
    "                distance = np.sqrt((peak_x - center[1])**2 + (peak_y - center[0])**2)\n",
    "                if distance > 15:\n",
    "                    axes[1,1].plot(peak_x, peak_y, 'rx', markersize=10)\n",
    "                    if distance == max_radius:\n",
    "                        axes[1,1].plot(peak_x, peak_y, 'go', markersize=15, fillstyle='none', linewidth=2)\n",
    "        axes[1,1].plot(center[1], center[0], 'b+', markersize=20)\n",
    "        axes[1,1].set_title('Peaks Marked (Green=Farthest)')\n",
    "        \n",
    "        radial_profile = []\n",
    "        for rad in range(0, int(min(center))):\n",
    "            ring_mask = (r >= rad) & (r < rad+1)\n",
    "            if ring_mask.any():\n",
    "                radial_profile.append(smoothed[ring_mask].max())\n",
    "        axes[1,2].plot(radial_profile)\n",
    "        if max_radius > 0:\n",
    "            axes[1,2].axvline(max_radius, color='g', linestyle='--', linewidth=2, label=f'Max peak: {max_radius:.1f}px')\n",
    "        axes[1,2].axhline(threshold, color='r', linestyle='--', label='threshold')\n",
    "        axes[1,2].set_xlabel('Radius (px)')\n",
    "        axes[1,2].set_ylabel('Max Power')\n",
    "        axes[1,2].legend()\n",
    "        axes[1,2].set_title('Radial Power Profile')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.suptitle(f'FFT Score: {fft_score:.3f} (max_r={max_radius:.1f}px)', y=1.00, fontsize=14)\n",
    "        plt.show()\n",
    "    \n",
    "    return contrast, fft_score, sim_im\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Setup seed data for the BO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter ranges based on your exploration\n",
    "param_ranges = {\n",
    "    'C10': (-8, 8),    # defocus\n",
    "    'C12a': (-10, 10), # twofold astigmatism (a)\n",
    "    'C12b': (-10, 10)  # twofold astigmatism (b)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create full grid (coarser for computational efficiency)\n",
    "n_grid = 7  # 7^3 = 343 points\n",
    "c10_grid = np.linspace(*param_ranges['C10'], n_grid)\n",
    "c12a_grid = np.linspace(*param_ranges['C12a'], n_grid)\n",
    "c12b_grid = np.linspace(*param_ranges['C12b'], n_grid)\n",
    "C10, C12A, C12B = np.meshgrid(c10_grid, c12a_grid, c12b_grid, indexing='ij')\n",
    "full_grid = np.stack([C10.flatten(), C12A.flatten(), C12B.flatten()], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample seed points\n",
    "n_seed = 4\n",
    "seed_indices = np.random.choice(len(full_grid), n_seed, replace=False)\n",
    "seed_points = full_grid[seed_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== QUERY SEED POINTS ==========\n",
    "print(f\"\\nQuerying {n_seed} seed points...\")\n",
    "seed_scores = []\n",
    "seed_images = []\n",
    "\n",
    "for i, (c10, c12a, c12b) in enumerate(seed_points):\n",
    "    contrast, fft_score, sim_im = get_stem_image_contrast_and_fft(c10, c12a, c12b, plot_diagnostics=True)\n",
    "    rewards = np.array((contrast, fft_score))\n",
    "    seed_scores.append(rewards)\n",
    "    seed_images.append(sim_im)\n",
    "    # print(f\"Seed {i+1}/{n_seed}, C23a={c23a:.2f}, C23b={c23b:.2f},  C21a={c21a:.2f}, C21b={c21b:.2f}, contrast={contrast:.4f}\")\n",
    "\n",
    "seed_scores = np.array(seed_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(seed_scores[:, 0], seed_scores[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Simple MOBO "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from botorch.models import SingleTaskGP\n",
    "from botorch.models.transforms import Normalize, Standardize\n",
    "from botorch.fit import fit_gpytorch_mll\n",
    "from botorch.acquisition import LogExpectedImprovement\n",
    "from botorch.optim import optimize_acqf\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "\n",
    "from botorch.models import MultiTaskGP\n",
    "from botorch.acquisition.multi_objective import qExpectedHypervolumeImprovement, qLogExpectedHypervolumeImprovement \n",
    "from botorch.utils.multi_objective.box_decompositions import NondominatedPartitioning\n",
    "from botorch.utils.multi_objective import is_non_dominated\n",
    "from botorch.utils.sampling import sample_simplex\n",
    "from botorch.utils.transforms import normalize, unnormalize\n",
    "\n",
    "# Set random seeds\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== INITIAL SEED POINTS (from previous code) ==========\n",
    "print(f\"Starting with {n_seed} seed points...\")\n",
    "print(f\"Best initial contrast: {seed_scores.max():.4f}\")\n",
    "\n",
    "# Convert to tensors\n",
    "train_X = torch.tensor(seed_points, dtype=torch.float64)\n",
    "train_Y = torch.tensor(seed_scores, dtype=torch.float64)\n",
    "\n",
    "# Define bounds for optimization\n",
    "bounds = torch.tensor([\n",
    "    [param_ranges['C10'][0], param_ranges['C12a'][0], param_ranges['C12b'][0]],  # lower bounds\n",
    "    [param_ranges['C10'][1], param_ranges['C12a'][1], param_ranges['C12b'][1]]   # upper bounds\n",
    "], dtype=torch.float64)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# ---- device & dtype ----\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "dtype = torch.float64\n",
    "\n",
    "torch.set_default_dtype(dtype)\n",
    "\n",
    "# move inputs/bounds to device+dtype\n",
    "train_X = train_X.to(device=device, dtype=dtype)\n",
    "train_Y = train_Y.to(device=device, dtype=dtype)\n",
    "bounds  = bounds.to(device=device, dtype=dtype)\n",
    "\n",
    "n_bo_steps = 50\n",
    "all_X = train_X.clone()\n",
    "all_Y = train_Y.clone()\n",
    "all_images = seed_images.copy()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Starting Multi-Objective Bayesian Optimization with EHVI\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "ref_point = train_Y.min(dim=0).values - 0.1 * train_Y.std(dim=0)\n",
    "print(f\"Reference point: {ref_point.detach().cpu().numpy()}\")\n",
    "\n",
    "for step in range(n_bo_steps):\n",
    "    print(f\"\\n--- BO Step {step + 1}/{n_bo_steps} ---\")\n",
    "    \n",
    "    # Train GP (model follows tensor's device/dtype)\n",
    "    print(\"Training Multi-Output GP...\")\n",
    "    gp_model = SingleTaskGP(\n",
    "        all_X, all_Y,\n",
    "        input_transform=Normalize(d=all_X.shape[-1]).to(device=device, dtype=dtype),\n",
    "        outcome_transform=Standardize(m=all_Y.shape[-1]).to(device=device, dtype=dtype),\n",
    "    ).to(device=device, dtype=dtype)\n",
    "    \n",
    "    gp_model.likelihood.noise_covar.initialize(noise=0.01)\n",
    "    mll = ExactMarginalLogLikelihood(gp_model.likelihood, gp_model).to(device=device, dtype=dtype)\n",
    "    fit_gpytorch_mll(mll)\n",
    "    \n",
    "    # EHVI acquisition\n",
    "    print(\"Computing Pareto frontier...\")\n",
    "    pareto_mask = is_non_dominated(all_Y)\n",
    "    pareto_Y = all_Y[pareto_mask]\n",
    "    print(f\"Pareto frontier size: {pareto_Y.shape[0]}\")\n",
    "    \n",
    "    partitioning = NondominatedPartitioning(ref_point=ref_point, Y=pareto_Y)\n",
    "    EHVI = qLogExpectedHypervolumeImprovement(\n",
    "        model=gp_model,\n",
    "        ref_point=ref_point.tolist(),\n",
    "        partitioning=partitioning,\n",
    "    )\n",
    "    \n",
    "    # Optimize\n",
    "    print(\"Optimizing acquisition function...\")\n",
    "    candidate, acq_value = optimize_acqf(\n",
    "        acq_function=EHVI,\n",
    "        bounds=bounds,\n",
    "        q=1,\n",
    "        num_restarts=10,\n",
    "        raw_samples=100,\n",
    "    )\n",
    "    \n",
    "    next_X = candidate.detach()\n",
    "    next_params = next_X.squeeze().detach().cpu().numpy()\n",
    "    print(f\"EHVI value: {acq_value:.6f}\")\n",
    "    \n",
    "    # Query simulator (returns CPU values)\n",
    "    print(\"Querying STEM simulator...\")\n",
    "    objective1, objective2, next_image = get_stem_image_contrast_and_fft(\n",
    "        next_params[0], next_params[1], next_params[2], plot_diagnostics=True\n",
    "    )\n",
    "    next_Y = torch.tensor([[objective1, objective2]], dtype=dtype, device=device)\n",
    "    \n",
    "    print(f\"Observed objectives: [{objective1:.4f}, {objective2:.4f}]\")\n",
    "    \n",
    "    # Update tensors on-device\n",
    "    all_X = torch.cat([all_X, next_X], dim=0)\n",
    "    all_Y = torch.cat([all_Y, next_Y], dim=0)\n",
    "    all_images.append(next_image)\n",
    "    \n",
    "    new_pareto_mask = is_non_dominated(all_Y)\n",
    "    if new_pareto_mask[-1]:\n",
    "        print(\"âœ“ NEW PARETO POINT!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Lets Visualize the Pareto-Frontier and see the MO-BO suggested solutions on it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== FIND EXTREME AND MID PARETO POINTS ==========\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Pareto Frontier Analysis\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "final_pareto_mask = is_non_dominated(all_Y)\n",
    "final_pareto_X = all_X[final_pareto_mask]\n",
    "final_pareto_Y = all_Y[final_pareto_mask]\n",
    "pareto_indices = torch.where(final_pareto_mask)[0].cpu().numpy()\n",
    "\n",
    "print(f\"Number of Pareto optimal points: {final_pareto_Y.shape[0]}\")\n",
    "\n",
    "# Find extreme points\n",
    "extreme_indices = []\n",
    "\n",
    "# Extreme for Objective 1\n",
    "max_obj1_idx = torch.argmax(final_pareto_Y[:, 0]).item()\n",
    "min_obj1_idx = torch.argmin(final_pareto_Y[:, 0]).item()\n",
    "\n",
    "# Extreme for Objective 2\n",
    "max_obj2_idx = torch.argmax(final_pareto_Y[:, 1]).item()\n",
    "min_obj2_idx = torch.argmin(final_pareto_Y[:, 1]).item()\n",
    "\n",
    "extreme_indices.extend([max_obj1_idx, min_obj1_idx, max_obj2_idx, min_obj2_idx])\n",
    "extreme_indices = list(set(extreme_indices))  # Remove duplicates\n",
    "\n",
    "# Find middle point (balanced trade-off)\n",
    "# Normalize objectives to [0,1] then find point closest to (0.5, 0.5)\n",
    "normalized_pareto_Y = (final_pareto_Y - final_pareto_Y.min(dim=0).values) / (final_pareto_Y.max(dim=0).values - final_pareto_Y.min(dim=0).values + 1e-8)\n",
    "distances_to_center = torch.norm(normalized_pareto_Y - 0.5, dim=1)\n",
    "mid_idx = torch.argmin(distances_to_center).item()\n",
    "\n",
    "# Combine: extremes + mid\n",
    "selected_indices = sorted(list(set(extreme_indices + [mid_idx])))\n",
    "\n",
    "print(f\"\\nSelected Pareto points for visualization: {len(selected_indices)}\")\n",
    "for idx in selected_indices:\n",
    "    pareto_idx = pareto_indices[idx]\n",
    "    params = all_X[pareto_idx].cpu().numpy()\n",
    "    obj1, obj2 = all_Y[pareto_idx, 0].item(), all_Y[pareto_idx, 1].item()\n",
    "    \n",
    "    label = \"\"\n",
    "    if idx == max_obj1_idx:\n",
    "        label += \"[MAX Obj1] \"\n",
    "    if idx == min_obj1_idx:\n",
    "        label += \"[MIN Obj1] \"\n",
    "    if idx == max_obj2_idx:\n",
    "        label += \"[MAX Obj2] \"\n",
    "    if idx == min_obj2_idx:\n",
    "        label += \"[MIN Obj2] \"\n",
    "    if idx == mid_idx:\n",
    "        label += \"[MID/Balanced] \"\n",
    "    \n",
    "    print(f\"  {label}\")\n",
    "    print(f\"    Obj1={obj1:.4f}, Obj2={obj2:.4f}\")\n",
    "    print(f\"    C10={params[0]:.2f}, C12a={params[1]:.2f}, C12b={params[2]:.2f}\")\n",
    "\n",
    "# ========== VISUALIZE ONLY EXTREME + MID PARETO IMAGES ==========\n",
    "n_selected = len(selected_indices)\n",
    "n_cols = min(3, n_selected)\n",
    "n_rows = int(np.ceil(n_selected / n_cols))\n",
    "\n",
    "fig = plt.figure(figsize=(7*n_cols, 7*n_rows))\n",
    "\n",
    "for plot_idx, pareto_idx_in_frontier in enumerate(selected_indices):\n",
    "    ax = fig.add_subplot(n_rows, n_cols, plot_idx + 1)\n",
    "    \n",
    "    pareto_idx = pareto_indices[pareto_idx_in_frontier]\n",
    "    img = all_images[pareto_idx]\n",
    "    params = all_X[pareto_idx].cpu().numpy()\n",
    "    obj1, obj2 = all_Y[pareto_idx, 0].item(), all_Y[pareto_idx, 1].item()\n",
    "    \n",
    "    # Determine label\n",
    "    label = \"\"\n",
    "    if pareto_idx_in_frontier == max_obj1_idx:\n",
    "        label = \"MAX Obj1\"\n",
    "        color = 'red'\n",
    "    elif pareto_idx_in_frontier == min_obj1_idx:\n",
    "        label = \"MIN Obj1\"\n",
    "        color = 'blue'\n",
    "    elif pareto_idx_in_frontier == max_obj2_idx:\n",
    "        label = \"MAX Obj2\"\n",
    "        color = 'green'\n",
    "    elif pareto_idx_in_frontier == min_obj2_idx:\n",
    "        label = \"MIN Obj2\"\n",
    "        color = 'orange'\n",
    "    elif pareto_idx_in_frontier == mid_idx:\n",
    "        label = \"BALANCED (Mid)\"\n",
    "        color = 'purple'\n",
    "    else:\n",
    "        label = \"Extreme\"\n",
    "        color = 'black'\n",
    "    \n",
    "\n",
    "    ax.imshow(np.array(img), cmap='gray')\n",
    "    ax.set_title(\n",
    "        f'{label}\\n'\n",
    "        f'Obj1={obj1:.4f}, Obj2={obj2:.4f}\\n'\n",
    "        f'C10={params[0]:.1f}, C12a={params[1]:.1f}\\n'\n",
    "        f'C12b={params[2]:.1f}\\n',\n",
    "        fontsize=12,\n",
    "        fontweight='bold',\n",
    "        color=color\n",
    "    )\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('pareto_extreme_mid_images.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# ========== COMBINED RESULTS PLOT ==========\n",
    "fig = plt.figure(figsize=(18, 6))\n",
    "\n",
    "# 1. Objective space\n",
    "ax1 = plt.subplot(1, 3, 1)\n",
    "ax1.scatter(all_Y[:, 0].cpu().numpy(), all_Y[:, 1].cpu().numpy(), \n",
    "           c='lightblue', s=150, alpha=0.6, edgecolors='gray',\n",
    "           label='All evaluations')\n",
    "ax1.scatter(final_pareto_Y[:, 0].cpu().numpy(), final_pareto_Y[:, 1].cpu().numpy(), \n",
    "           c='lightcoral', s=200, alpha=0.5, edgecolors='black', \n",
    "           linewidths=1, label='Pareto frontier')\n",
    "\n",
    "# Highlight extreme and mid points\n",
    "colors = []\n",
    "labels_legend = []\n",
    "for idx in selected_indices:\n",
    "    if idx == max_obj1_idx:\n",
    "        colors.append('red')\n",
    "        if 'MAX Obj1' not in labels_legend:\n",
    "            labels_legend.append('MAX Obj1')\n",
    "    elif idx == max_obj2_idx:\n",
    "        colors.append('green')\n",
    "        if 'MAX Obj2' not in labels_legend:\n",
    "            labels_legend.append('MAX Obj2')\n",
    "    elif idx == mid_idx:\n",
    "        colors.append('purple')\n",
    "        if 'Balanced' not in labels_legend:\n",
    "            labels_legend.append('Balanced')\n",
    "    else:\n",
    "        colors.append('orange')\n",
    "\n",
    "for idx, color in zip(selected_indices, colors):\n",
    "    ax1.scatter(final_pareto_Y[idx, 0].cpu().numpy(), final_pareto_Y[idx, 1].cpu().numpy(),\n",
    "               c=color, s=400, marker='*', edgecolors='black', linewidths=2, zorder=10)\n",
    "\n",
    "ax1.set_xlabel('Objective 1 (Contrast)', fontsize=12)\n",
    "ax1.set_ylabel('Objective 2 (Other Metric)', fontsize=12)\n",
    "ax1.set_title('Pareto Frontier (â˜… = Extreme/Mid points)', fontsize=14, fontweight='bold')\n",
    "ax1.legend(fontsize=10)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. BO progress\n",
    "ax2 = plt.subplot(1, 3, 2)\n",
    "iterations = range(len(all_Y))\n",
    "ax2.plot(iterations, all_Y[:, 0].cpu().numpy(), 'o-', label='Objective 1', \n",
    "        alpha=0.7, linewidth=2, markersize=8)\n",
    "ax2.plot(iterations, all_Y[:, 1].cpu().numpy(), 's-', label='Objective 2', \n",
    "        alpha=0.7, linewidth=2, markersize=8)\n",
    "ax2.axvline(len(train_Y)-1, color='red', linestyle='--', \n",
    "          label='BO start', linewidth=2)\n",
    "ax2.set_xlabel('Iteration', fontsize=12)\n",
    "ax2.set_ylabel('Objective Value', fontsize=12)\n",
    "ax2.set_title('BO Progress', fontsize=14, fontweight='bold')\n",
    "ax2.legend(fontsize=10)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Hypervolume\n",
    "from botorch.utils.multi_objective.hypervolume import Hypervolume\n",
    "\n",
    "hv_computer = Hypervolume(ref_point=ref_point)\n",
    "hypervolumes = []\n",
    "for i in range(len(train_Y), len(all_Y) + 1):\n",
    "    current_Y = all_Y[:i]\n",
    "    pareto_mask_i = is_non_dominated(current_Y)\n",
    "    pareto_Y_i = current_Y[pareto_mask_i]\n",
    "    hv = hv_computer.compute(pareto_Y_i)\n",
    "    hypervolumes.append(hv)\n",
    "\n",
    "ax3 = plt.subplot(1, 3, 3)\n",
    "ax3.plot(range(len(train_Y), len(all_Y) + 1), hypervolumes, 'o-', \n",
    "        linewidth=2, markersize=8, color='purple')\n",
    "ax3.set_xlabel('Iteration', fontsize=12)\n",
    "ax3.set_ylabel('Hypervolume', fontsize=12)\n",
    "ax3.set_title('Hypervolume Improvement', fontsize=14, fontweight='bold')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('multi_objective_summary.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n=== SUMMARY ===\")\n",
    "print(f\"Total evaluations: {len(all_Y)}\")\n",
    "print(f\"Pareto frontier size: {len(pareto_indices)}\")\n",
    "print(f\"Extreme + Mid points shown: {len(selected_indices)}\")\n",
    "print(f\"Final hypervolume: {hypervolumes[-1]:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "asyncroscopy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
